{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Reads the Hagrid static gesture dataset saved as a compressed npz file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_hagrid_saved_npz(npz_path: str) -> pd.DataFrame:\n",
    "    npz = np.load(npz_path, allow_pickle=True)\n",
    "    arr = np.array(npz[npz.files[0]])  # use first array (e.g. 'arr_0' if unnamed)\n",
    "    if arr.ndim != 2 or arr.shape[1] != 64:\n",
    "        raise ValueError(f\"Expected shape (N,64), got {arr.shape}\")\n",
    "    labels = arr[:, 0]\n",
    "    X = arr[:, 1:].astype(float)  # 63 feature columns\n",
    "\n",
    "    cols = []\n",
    "    for i in range(21):\n",
    "        cols += [f\"x{i}\", f\"y{i}\", f\"z{i}\"]\n",
    "\n",
    "    df = pd.DataFrame(X, columns=cols)\n",
    "    df.insert(0, \"label\", labels)\n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "Hagrid = load_hagrid_saved_npz(\"output/compressed/hagrid_static_gestures.npz\")\n",
    "Hagrid.head() # shows the first few rows\n",
    "Hagrid.groupby(\"label\").size() # shows counts per label"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def add_empty_rows(df: pd.DataFrame, n: int = 5, label_value=None, feature_fill=np.nan) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a new DataFrame with `n` appended rows:\n",
    "    - first column is treated as the label and set to `label_value` (e.g. None)\n",
    "    - remaining columns are filled with `feature_fill` (default NaN)\n",
    "    \"\"\"\n",
    "    if n <= 0:\n",
    "        return df.copy()\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    cols = df_copy.columns.tolist()\n",
    "    label_col = cols[0]\n",
    "    feature_cols = cols[1:]\n",
    "\n",
    "    # Ensure label column can hold None\n",
    "    df_copy[label_col] = df_copy[label_col].astype(object)\n",
    "\n",
    "    data = {label_col: [label_value] * n}\n",
    "    for c in feature_cols:\n",
    "        data[c] = [feature_fill] * n\n",
    "\n",
    "    empty_df = pd.DataFrame(data, columns=cols)\n",
    "    return pd.concat([df_copy, empty_df], ignore_index=True)\n"
   ],
   "id": "cf3a4111fc32a6c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Hagrid = add_empty_rows(Hagrid, n =20000, label_value=\"None\")\n",
    "# shuffle the DataFrame rows\n",
    "shuffled_df = Hagrid.sample(frac=1).reset_index(drop=True)\n",
    "print(shuffled_df.groupby(\"label\").size())\n",
    "shuffled_df.head()"
   ],
   "id": "98d4a0d94b5ae245",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check registered labels\n",
    "registered_labels = shuffled_df[\"label\"].unique()\n",
    "print(F\"Registered labels: {registered_labels}\")\n"
   ],
   "id": "5b7c69755e5fd598",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Prepare data for training:\n",
    "-Remove rows with label \"None\"\n",
    "-Normalize features to [0,1]\n",
    "-Encode labels\n",
    "-Split into train and test sets\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "# Filter out rows where label is \"None\"\n",
    "mask = shuffled_df['label'] != \"None\"\n",
    "filtered_df = shuffled_df[mask]\n",
    "\n",
    "labels = filtered_df['label']\n",
    "features = filtered_df.iloc[:, 1:].astype(float)\n",
    "print(\"Features shape after removing 'None':\", features.shape)\n",
    "\n",
    "# Normalize features to [0,1]\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(features.values)\n",
    "\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(labels)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)\n",
    "print(encoder.classes_)\n"
   ],
   "id": "2f02444538763ab3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(63,)),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(len(encoder.classes_), activation=\"softmax\")\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32\n",
    ")\n"
   ],
   "id": "3587918bdc151bb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot training history to see how loss and accuracy evolved\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'])\n",
    "axes[0].plot(history.history['val_loss'])\n",
    "axes[0].set_title(\"Loss\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].legend([\"Train\", \"Val\"])\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history.history['accuracy'])\n",
    "axes[1].plot(history.history['val_accuracy'])\n",
    "axes[1].set_title(\"Accuracy\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].legend([\"Train\", \"Val\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "b0268d6d71e4e87d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check which labels are present in X_test\n",
    "unique_labels_test = [encoder.classes_[i] for i in np.unique(y_test)]\n",
    "print(\"Labels in X_test:\", unique_labels_test)\n"
   ],
   "id": "6faa0638e0f46994",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_random_sample_from_test(X_test, y_test, encoder):\n",
    "    \"\"\"\n",
    "    Randomly select a label from X_test that exists, then return a random sample\n",
    "    and its true label.\n",
    "    \"\"\"\n",
    "    # Get unique label IDs in the test set\n",
    "    available_label_ids = np.unique(y_test)\n",
    "\n",
    "    # Pick one label ID at random\n",
    "    label_id = np.random.choice(available_label_ids)\n",
    "\n",
    "    # Pick a random sample with that label\n",
    "    indices = np.where(y_test == label_id)[0]\n",
    "    idx = np.random.choice(indices)\n",
    "\n",
    "    # Return features and true label\n",
    "    X_sample = X_test[idx]\n",
    "    y_sample = y_test[idx]\n",
    "\n",
    "    # Convert label ID back to label name\n",
    "    label_name = encoder.classes_[label_id]\n",
    "\n",
    "    return X_sample, y_sample, label_name\n",
    "\n",
    "# Get a random sample from test set\n",
    "X_sample, y_sample, actual_label = get_random_sample_from_test(X_test, y_test, encoder)\n",
    "\n",
    "# Prepare for prediction\n",
    "sample = X_sample.reshape(1, -1)\n",
    "pred = model.predict(sample)\n",
    "\n",
    "predicted_label = encoder.classes_[np.argmax(pred)]\n",
    "\n",
    "print(\"Predicted:\", predicted_label)\n",
    "print(\"Actual   :\", actual_label)\n"
   ],
   "id": "78ff1956daafbeff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_random_samples(X_test, y_test, encoder, model, n=100):\n",
    "    # Evaluate model accuracy over n random samples from X_test\n",
    "    correct = 0\n",
    "\n",
    "    for _ in range(n):\n",
    "        # Get a random sample\n",
    "        available_label_ids = np.unique(y_test)\n",
    "        label_id = np.random.choice(available_label_ids)\n",
    "        indices = np.where(y_test == label_id)[0]\n",
    "        idx = np.random.choice(indices)\n",
    "\n",
    "        X_sample = X_test[idx].reshape(1, -1)\n",
    "        y_sample = y_test[idx]\n",
    "\n",
    "        # Predict\n",
    "        pred = model.predict(X_sample, verbose=0)\n",
    "        predicted_label = encoder.classes_[np.argmax(pred)]\n",
    "        actual_label = encoder.classes_[y_sample]\n",
    "\n",
    "        if predicted_label == actual_label:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / n\n",
    "    print(f\"Random-sample accuracy over {n} samples: {accuracy:.2%}\")\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_random_samples(X_test, y_test, encoder, model, n=100)\n"
   ],
   "id": "b86afdbad4308490",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Export the trained model and label mapping\n",
    ":returns a folder model/hagrid_vN where N is the next version number\n",
    "- model saved in Keras (.keras) or SavedModel format\n",
    "- labels saved in labels.json\n",
    "\"\"\"\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "\n",
    "# Base model directory\n",
    "BASE_MODEL_DIR = \"model/hagrid\"\n",
    "\n",
    "# Ensure base directory exists\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# Find existing versions\n",
    "existing_versions = glob.glob(f\"{BASE_MODEL_DIR}_v*\")\n",
    "version_numbers = [\n",
    "    int(v.split(\"_v\")[-1]) for v in existing_versions if v.split(\"_v\")[-1].isdigit()\n",
    "]\n",
    "next_version = max(version_numbers, default=0) + 1\n",
    "\n",
    "# Create version folder\n",
    "VERSION_DIR = f\"{BASE_MODEL_DIR}_v{next_version}\"\n",
    "os.makedirs(VERSION_DIR, exist_ok=True)\n",
    "\n",
    "# Choose export format\n",
    "EXPORT_FORMAT = \"keras\"  # options: \"keras\" or \"savedmodel\"\n",
    "\n",
    "if EXPORT_FORMAT == \"keras\":\n",
    "    MODEL_FILE = os.path.join(VERSION_DIR, \"model.keras\")\n",
    "    model.save(MODEL_FILE)\n",
    "    print(f\"Saved Keras model to {MODEL_FILE}\")\n",
    "else:  # SavedModel format\n",
    "    MODEL_DIR = os.path.join(VERSION_DIR, \"saved_model\")\n",
    "    model.export(MODEL_DIR)\n",
    "    print(f\"Saved SavedModel to {MODEL_DIR}\")\n",
    "\n",
    "# Save label mapping inside the same folder\n",
    "LABELS_FILE = os.path.join(VERSION_DIR, \"labels.json\")\n",
    "label_mapping = {int(i): label for i, label in enumerate(encoder.classes_)}\n",
    "with open(LABELS_FILE, \"w\") as f:\n",
    "    json.dump(label_mapping, f, indent=4)\n",
    "\n",
    "print(f\"Saved labels to {LABELS_FILE}\")\n",
    "print(f\"All files for version {next_version} are in {VERSION_DIR}\")\n",
    "\n",
    "\n"
   ],
   "id": "a4c723425b66818b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"Convert the saved Keras model to TensorFlow Lite format\"\"\"\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Version directory\n",
    "VERSION_DIR = \"model/hagrid_v1\"\n",
    "keras_model_file = os.path.join(VERSION_DIR, \"model.keras\")\n",
    "tflite_model_file = os.path.join(VERSION_DIR, \"model.tflite\")\n",
    "\n",
    "# Load Keras model\n",
    "model = tf.keras.models.load_model(keras_model_file)\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open(tflite_model_file, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved to {tflite_model_file}\")\n"
   ],
   "id": "ce2732774732afa7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
