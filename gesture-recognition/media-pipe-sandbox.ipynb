{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "You need to install these modules before you can use them\n",
    "pip install <module>\n",
    "\n",
    "\n",
    "This file is were i am experimenting with landmark extraction. i use open cv to read video from files and run the frames through media pipe to extract the landmark data.\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ],
   "id": "7db6741d98ab18f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mpHands = mp.solutions.hands\n",
    "mpPose = mp.solutions.pose\n",
    "# mpFace = mp.solutions.\n",
    "mpDraw = mp.solutions.drawing_utils\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# sets default configurations for the hand and pose detection\n",
    "hands = mpHands.Hands(max_num_hands=2, min_detection_confidence=0.7)\n",
    "pose = mpPose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n"
   ],
   "id": "925c38bcc1b6e894",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Reading From a video file\n",
    "cap = cv2.VideoCapture('videos/SamplePushups.mp4')\n",
    "\n",
    "cv2.namedWindow('MediaPipe', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('MediaPipe', 960, 540)  # width, height\n",
    "\n",
    "while cap.isOpened():\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    try:\n",
    "        #convert to RGB format\n",
    "        RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # generate landmark data\n",
    "        results = pose.process(RGB)\n",
    "        print(results.pose_landmarks)\n",
    "        #drawwing landmarks\n",
    "        mpDraw.draw_landmarks(frame, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow('MediaPipe', frame)\n",
    "    except:\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "fabbba187ba991ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "* This uses the pose model from media pipe on live video feed to track landmarks\n",
    "\"\"\"\n",
    "#Reading From a live camera feed.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow('MediaPipe', cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow('MediaPipe', 960, 540)  # width, height\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 960)  # width\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 540)  # height\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    x, y, c = frame.shape\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    poseResults = pose.process(framergb)\n",
    "\n",
    "    mpDraw.draw_landmarks(frame, poseResults.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "\n",
    "    cv2.imshow('MediaPipe', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "d15b056ef962a8fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "* Reads from live video feed to track landmarks for hand data\n",
    "\"\"\"\n",
    "#Reading From a video file\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow('MediaPipe', cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow('MediaPipe', 960, 540)  # width, height\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 960)  # width\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 540)  # height\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    x, y, c = frame.shape\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(framergb)\n",
    "    if results.multi_hand_landmarks:\n",
    "        landmarks = []\n",
    "        for handslms in results.multi_hand_landmarks:\n",
    "            for lm in handslms.landmark:\n",
    "                lmx = int(lm.x * x)\n",
    "                lmy = int(lm.y * y)\n",
    "                landmarks.append([lmx, lmy])\n",
    "            mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "    cv2.imshow('MediaPipe', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "82027f8755703a85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "* Reads from live video feed to track landmarks for hand and pose data\n",
    "* Press E - to show all landmarks\n",
    "* Press P - to show pose data\n",
    "* Press Q - to exit\n",
    "* Press H - to show hand data\n",
    "* Press R - to hide all landmarks\n",
    "\"\"\"\n",
    "#Reading From a video file\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow('MediaPipe', cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow('MediaPipe', 960, 540)  # width, height\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)  # width\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)  # height\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "showHands = True\n",
    "showPose = True\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    x, y, c = frame.shape\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    if showHands:\n",
    "        results = hands.process(framergb)\n",
    "    if showPose:\n",
    "        poseResults = pose.process(framergb)\n",
    "    if showHands:\n",
    "        if results.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for handslms in results.multi_hand_landmarks:\n",
    "                for lm in handslms.landmark:\n",
    "                    lmx = int(lm.x * x)\n",
    "                    lmy = int(lm.y * y)\n",
    "                    landmarks.append([lmx, lmy])\n",
    "                mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "    if showPose:\n",
    "        mpDraw.draw_landmarks(frame, poseResults.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "\n",
    "    cv2.imshow('MediaPipe', frame)\n",
    "    keybind = cv2.waitKey(1) & 0xFF\n",
    "    if keybind == ord('q'):\n",
    "        break\n",
    "    if keybind == ord('p'):\n",
    "        showPose = not showPose\n",
    "    if keybind == ord('h'):\n",
    "        showHands = not showHands\n",
    "    if keybind == ord('e'):\n",
    "        showPose = True\n",
    "        showHands = True\n",
    "    if keybind == ord('r'):\n",
    "        showPose = False\n",
    "        showHands = False\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "e0003c0342ecf98c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
